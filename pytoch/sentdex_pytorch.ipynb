{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentdex_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2Bfuj8MaTfXx",
        "W34nQTSwTiAB",
        "d_XFXZKae5gC",
        "APC4PWZeQBjS",
        "J0-wvc3qX6bJ",
        "Tf4Sctk8gBOF"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bfuj8MaTfXx",
        "colab_type": "text"
      },
      "source": [
        "##p1 Introduction - Deep Learning and Neural Networks with Python and Pytorch p.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i20Bg7AuStJf",
        "colab_type": "code",
        "outputId": "561e897e-6372-4a46-e5aa-6c4a396863c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.Tensor([5,3])\n",
        "y = torch.Tensor([2,1])\n",
        "\n",
        "print(x*y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10.,  3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXe9kWsHS5sZ",
        "colab_type": "code",
        "outputId": "168ea59e-288e-401b-da38-b9521c6ff666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.zeros([2,5])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCAUjnIZS5vK",
        "colab_type": "code",
        "outputId": "774deaae-6502-484a-f9ca-8d7eb4f729f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y = torch.rand([2,5])\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1656, 0.3761, 0.4543, 0.8688, 0.8716],\n",
            "        [0.8613, 0.3042, 0.2068, 0.3315, 0.6292]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c16F-1BYS5x4",
        "colab_type": "code",
        "outputId": "1925be96-73bc-49a4-c576-e7054eb5984a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y.view([1,10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1656, 0.3761, 0.4543, 0.8688, 0.8716, 0.8613, 0.3042, 0.2068, 0.3315,\n",
              "         0.6292]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jHlJ1urTL7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "??y.view()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sir8I4RDTL9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W34nQTSwTiAB",
        "colab_type": "text"
      },
      "source": [
        "##p2 Data - Deep Learning and Neural Networks with Python and Pytorch p.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD8syU7jTjbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "from torchvision import transforms,datasets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy_su1fTTjgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train = datasets.MNIST('',train=True, download=True, transform=transforms.Compose([\n",
        "                                                                                   transforms.ToTensor()\n",
        "])) \n",
        "\n",
        "test = datasets.MNIST('',train=False, download=True, transform=transforms.Compose([\n",
        "                                                                                   transforms.ToTensor()\n",
        "])) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVGBFwOnVMjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
        "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjAq2yiLVMl-",
        "colab_type": "code",
        "outputId": "8fff4bf1-520b-433c-c4d0-07cf1b7a1ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "for data in trainset:\n",
        "    print(data)\n",
        "    break\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([6, 9, 1, 2, 8, 0, 4, 4, 6, 9])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_0fteXjaXsi",
        "colab_type": "code",
        "outputId": "0f0b4db1-d227-46e6-8347-89606f8a776c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = data[0][0], data[1][0]\n",
        "print(data[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([6, 9, 1, 2, 8, 0, 4, 4, 6, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cq6UHn5at5o",
        "colab_type": "code",
        "outputId": "b40ee719-9200-4389-eb7c-13d5f745ae61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWPUbdSYbkkY",
        "colab_type": "code",
        "outputId": "b8ac80be-82d1-416c-ec51-26d04514aabe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X.view(28,28))\n",
        "# plt.imshow(X.view(28,28))\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQfHHiVeKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMoEE-LCd_25",
        "colab_type": "code",
        "outputId": "d2425cad-ca54-41e1-874a-23a30f0d2835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# 确认是不是 缩到1的范围内了\n",
        "data[0][0][0][3] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1647,\n",
              "        0.9020, 0.9961, 0.4235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COorxo_5d_5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 看数据的平衡情况"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2EHCysLelww",
        "colab_type": "code",
        "outputId": "c52f5ae1-c04e-4767-e757-5d6101837f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "total = 0\n",
        "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
        "\n",
        "\n",
        "for data in trainset:\n",
        "    Xs, ys = data\n",
        "    for y in ys:\n",
        "        counter_dict[int(y)] += 1\n",
        "        total += 1\n",
        "\n",
        "print(counter_dict)\n",
        "\n",
        "for i in counter_dict:\n",
        "    print(f\"{i}: {counter_dict[i]/total*100.0}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
            "0: 9.871666666666666%\n",
            "1: 11.236666666666666%\n",
            "2: 9.93%\n",
            "3: 10.218333333333334%\n",
            "4: 9.736666666666666%\n",
            "5: 9.035%\n",
            "6: 9.863333333333333%\n",
            "7: 10.441666666666666%\n",
            "8: 9.751666666666667%\n",
            "9: 9.915000000000001%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iviZ2csOelza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUwRP1aqVjTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainset)\n",
        "images, labels = dataiter.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp1169qLYM3D",
        "colab_type": "code",
        "outputId": "3964bcbb-b12d-444f-b803-13f3b18b9a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 显示图片\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# imshow(X)\n",
        "# # 打印图片标签\n",
        "# print(' '.join('%5s' % classes[labels[j]] for j in range(10)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB4CAYAAADi1gmcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai0x_kvgcwkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_XFXZKae5gC",
        "colab_type": "text"
      },
      "source": [
        "## p3 Building our Neural Network - Deep Learning and Neural Networks with Python and Pytorch p.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfbvuk46e62j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://pythonprogramming.net/building-deep-learning-neural-network-pytorch/?completed=/data-deep-learning-neural-network-pytorch/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjzzI3xKe65r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qIUXrELprH",
        "colab_type": "code",
        "outputId": "2ea77400-d500-4bdf-c95c-bf54b0e64ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "        # return x\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuvGwPXnLp8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 虚拟一个数据\n",
        "X = torch.randn((28,28))\n",
        "X = X.view(-1,28*28)\n",
        "output = net(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDisjwEdPmQt",
        "colab_type": "code",
        "outputId": "081a7b8a-7fb4-4b2e-8e8a-6ffca0f8f750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0636,  0.0364, -0.0196, -0.1690, -0.1548, -0.1754,  0.0233, -0.0622,\n",
              "          0.0848,  0.0406]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APC4PWZeQBjS",
        "colab_type": "text"
      },
      "source": [
        "## p4 Training Neural Network - Deep Learning and Neural Networks with Python and Pytorch p.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzAO6k_xQCgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZEpDNh1QGok",
        "colab_type": "code",
        "outputId": "21bbfa13-eea6-450c-90be-47a0beffca82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "for epoch in range(3): # 3 full passes over the data\n",
        "    for data in trainset:  # `data` is a batch of data\n",
        "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
        "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
        "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
        "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
        "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
        "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
        "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0072, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0031, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0043, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_G3rIfEVO_M",
        "colab_type": "code",
        "outputId": "4fff8442-fc70-4447-c9ce-68f80f177c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in testset:\n",
        "    X,y = data\n",
        "    output = net(X.view(-1,784))\n",
        "    #print(output)\n",
        "    for idx,i in enumerate(output):\n",
        "      #print(torch.argmax(i),y[idx])\n",
        "      if torch.argmax(i) == y[idx]:\n",
        "        correct += 1\n",
        "      total += 1\n",
        "print(\"Accuracy: \",round(correct/total,3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7wf-X4eVdmV",
        "colab_type": "code",
        "outputId": "f26c73a6-4ec6-4d8c-c0dd-66c596b75c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X[0].view(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npAg/kNT/AcuyB/+MFbVaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foMaZQxKW6K0",
        "colab_type": "code",
        "outputId": "9c4c5ad1-e7f5-4d43-edb1-f6a46899c692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(torch.argmax(net(X[0].view(-1,784))[0]))\n",
        "# print(torch.argmax(net(X[0].view(-1,784))[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0-wvc3qX6bJ",
        "colab_type": "text"
      },
      "source": [
        "##p5 Convolutional Neural Networks - Deep Learning and Neural Networks with Python and Pytorch p.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4oaoXsRX7Ph",
        "colab_type": "code",
        "outputId": "b4b0d117-e7ad-45f1-d400-4cd3af0995da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip \\\n",
        "    -O /tmp/catvsdog.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-18 10:25:41--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 2.21.40.213, 2a02:26f0:6b:5a5::e59, 2a02:26f0:6b:5b3::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|2.21.40.213|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/catvsdog.zip’\n",
            "\n",
            "/tmp/catvsdog.zip   100%[===================>] 786.68M   141MB/s    in 5.4s    \n",
            "\n",
            "2019-10-18 10:25:47 (146 MB/s) - ‘/tmp/catvsdog.zip’ saved [824894548/824894548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aPC97I6ZnGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/catvsdog.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IEh9m89abkD",
        "colab_type": "code",
        "outputId": "a34faea6-5020-4cc9-c383-6da19d24b02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip install opencv-python numpy tqdm matplotlib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.7.28)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY-E5oyxabmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9evIsPwbabo2",
        "colab_type": "code",
        "outputId": "97918f86-8d3f-4a54-c98e-1e1c84317440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "REBUILD_DATA = True # set to true to one once, then back to false unless you want to change something in your training data.\n",
        "\n",
        "\n",
        "class DogsVSCats():\n",
        "    IMG_SIZE = 50\n",
        "    CATS = \"/tmp/PetImages/Cat\"\n",
        "    DOGS = \"/tmp/PetImages/Dog\"\n",
        "    TESTING = \"/tmp/PetImaos.listdir(path)ges/Testing\"\n",
        "    LABELS = {CATS: 0, DOGS: 1}\n",
        "    training_data = []\n",
        "    \n",
        "    catcount = 0\n",
        "    dogcount = 0\n",
        "\n",
        "    def make_training_data(self):\n",
        "        for label in self.LABELS:\n",
        "            print(label)\n",
        "            for f in tqdm(os.listdir(label)):\n",
        "                if \"jpg\" in f:\n",
        "                    try:\n",
        "                        path = os.path.join(label, f)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
        "                        #print(np.eye(2)[self.LABELS[label]])\n",
        "\n",
        "                        if label == self.CATS:\n",
        "                            self.catcount += 1\n",
        "                        elif label == self.DOGS:\n",
        "                            self.dogcount += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "                        #print(label, f, str(e))\n",
        "\n",
        "        np.random.shuffle(self.training_data)\n",
        "        np.save(\"training_data.npy\", self.training_data)\n",
        "        print('Cats:',dogsvcats.catcount)\n",
        "        print('Dogs:',dogsvcats.dogcount)\n",
        "\n",
        "if REBUILD_DATA:\n",
        "    dogsvcats = DogsVSCats()\n",
        "    dogsvcats.make_training_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 73/12501 [00:00<00:17, 725.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/tmp/PetImages/Cat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12501/12501 [00:12<00:00, 1014.50it/s]\n",
            "  1%|          | 89/12501 [00:00<00:14, 884.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/tmp/PetImages/Dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12501/12501 [00:13<00:00, 949.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cats: 12476\n",
            "Dogs: 12470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lih_-m9tabru",
        "colab_type": "code",
        "outputId": "1acee70a-30f5-4456-d752-6c294266ff35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(os.listdir('/tmp/PetImages/Cat')) + len(os.listdir('/tmp/PetImages/Dog'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APrfwTgzbVVq",
        "colab_type": "code",
        "outputId": "9d09ed7e-b3fe-4f57-8619-07fab3fa2a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.listdir(\"/tmp/PetImages\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dog', 'Cat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuzZuOLjcbn1",
        "colab_type": "code",
        "outputId": "a87fc8fb-5f90-483e-c684-eaff3b9e00c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.eye(2)[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvbolpVzcthh",
        "colab_type": "code",
        "outputId": "3cbf8bc7-cb30-4348-ece1-a5740894dd84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
        "print(len(training_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0wF8YhjctkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in training_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXAFxqvTctpd",
        "colab_type": "code",
        "outputId": "5eca1943-f350-4a4a-9640-857af1f9ed42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X[0], cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f071221df28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbXwhKkQbX4gK0cYXokK08YWokP8HeiA/LxMLoFYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGNV6hqEfjmv",
        "colab_type": "code",
        "outputId": "3eca05b0-9b30-40ca-ee11-01b54092b0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y[0]) # 狗"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f9c0f180-7130-4d8b-c399-01676314c378",
        "id": "CWTapbNAlQVi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLbHPRWoksZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRJkKKxyksca",
        "colab_type": "code",
        "outputId": "99c67c43-0d34-4351-b9b2-2fd430649353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "shutil.copyfile('/content/training_data.npy', '/content/drive/My Drive/Colab Notebooks/sentdex/training_data.npy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/sentdex/training_data.npy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf4Sctk8gBOF",
        "colab_type": "text"
      },
      "source": [
        "## p6 Convolutional Neural Nework Model - Deep Learning and Neural Networks with Python and Pytorch p.6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "falaOWfIflXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mf2tFfEflaG",
        "colab_type": "code",
        "outputId": "b49f853b-f8f0-40a9-c90b-a4098e27cd6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# 自己可以直接算图像大小的\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1,32,5)  # input is 1 image, 32 output channels, 5x5 kernel / window\n",
        "    self.conv2 = nn.Conv2d(32,64,5)\n",
        "    self.conv3 = nn.Conv2d(64,128,5)\n",
        "    self.fc1 = nn.Linear(512, 512) #flattening.\n",
        "    self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
        "    x = x.view(-1, 512) \n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x) \n",
        "\n",
        "    return F.softmax(x, dim=1)\n",
        "\n",
        "net = Net()\n",
        "print(net)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdV5fgWYflco",
        "colab_type": "code",
        "outputId": "c4bf05f5-2409-41ca-c4ff-119a6284459f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# 作者给的一种不用计算图像大小的方法\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # just run the init of parent class (nn.Module)\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "\n",
        "        x = torch.randn(50,50).view(-1,1,50,50)\n",
        "        self._to_linear = None\n",
        "        self.convs(x)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
        "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
        "\n",
        "    def convs(self, x):\n",
        "        # max pooling over 2x2\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
        "\n",
        "        if self._to_linear is None:\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guGz8sPOflff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlPzYNqJfjpF",
        "colab_type": "code",
        "outputId": "f2e7643b-9ce5-443c-fd09-1b94d233141f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
        "print(len(training_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDxUKuSHfjrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in training_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKZ7pL3Pfjui",
        "colab_type": "code",
        "outputId": "fbbe2c52-776f-4827-ea23-37b0f55a09c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
        "val_size = int(len(X)*VAL_PCT)\n",
        "print(val_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXmyyhqof_3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = X[:-val_size]\n",
        "train_y = y[:-val_size]\n",
        "\n",
        "test_X = X[-val_size:]\n",
        "test_y = y[-val_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVvdiIXOpqqs",
        "colab_type": "code",
        "outputId": "62248c5e-84c6-4b83-9463-ab6a494f71b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(train_X), len(test_X))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22452 2494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlMM5jAnpqtW",
        "colab_type": "code",
        "outputId": "d6ed4d1c-30db-44eb-8178-2d1fae1315dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 训练\n",
        "from tqdm import tqdm\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
        "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
        "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
        "        # print(i+BATCH_SIZE)\n",
        "        batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "        net.zero_grad()\n",
        "\n",
        "        outputs = net(batch_X)\n",
        "        loss = loss_function(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()    # Does the update\n",
        "\n",
        "    print(f\"Epoch: {epoch}. Loss: {loss}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [01:34<00:00,  2.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0. Loss: 0.20433443784713745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx17RrSKpqwi",
        "colab_type": "code",
        "outputId": "93b5fcb2-ef71-4bb9-fe60-388dd3a63fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 验证集\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(len(test_X))):\n",
        "        real_class = torch.argmax(test_y[i])\n",
        "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]  # returns a list, \n",
        "        predicted_class = torch.argmax(net_out)\n",
        "\n",
        "        if predicted_class == real_class:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "print(\"Accuracy: \", round(correct/total, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2494/2494 [00:05<00:00, 489.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT2rcjmXt0t_",
        "colab_type": "text"
      },
      "source": [
        "## p7 Running on the GPU - Deep Learning and Neural Networks with Python and Pytorch p.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgCLLOMauVSM",
        "colab_type": "text"
      },
      "source": [
        "If you're using a server, you will want to grab the data, extract it, and get jupyter notebook:\n",
        "\n",
        "wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
        "sudo apt-get install unzip\n",
        "unzip kagglecatsanddogs_3367a.zip\n",
        "pip3 install jupyterlab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrj90CTotz6n",
        "colab_type": "code",
        "outputId": "2483626e-361b-452c-df8b-0485408a6ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 检查gpu是否可用\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUBpmMPitz-J",
        "colab_type": "code",
        "outputId": "e2c64927-dc3c-4fc9-a34d-d8ac9d6b811e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eUEgIjQt0Eq",
        "colab_type": "code",
        "outputId": "a1e6353f-09ec-4164-d51e-002a2c0c05a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "REBUILD_DATA = False # set to true to one once, then back to false unless you want to change something in your training data.\n",
        "\n",
        "class DogsVSCats():\n",
        "    IMG_SIZE = 50\n",
        "    CATS = \"PetImages/Cat\"\n",
        "    DOGS = \"PetImages/Dog\"\n",
        "    TESTING = \"PetImages/Testing\"\n",
        "    LABELS = {CATS: 0, DOGS: 1}\n",
        "    training_data = []\n",
        "\n",
        "    catcount = 0\n",
        "    dogcount = 0\n",
        "\n",
        "    def make_training_data(self):\n",
        "        for label in self.LABELS:\n",
        "            print(label)\n",
        "            for f in tqdm(os.listdir(label)):\n",
        "                if \"jpg\" in f:\n",
        "                    try:\n",
        "                        path = os.path.join(label, f)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
        "                        #print(np.eye(2)[self.LABELS[label]])\n",
        "\n",
        "                        if label == self.CATS:\n",
        "                            self.catcount += 1\n",
        "                        elif label == self.DOGS:\n",
        "                            self.dogcount += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "                        #print(label, f, str(e))\n",
        "\n",
        "        np.random.shuffle(self.training_data)\n",
        "        np.save(\"training_data.npy\", self.training_data)\n",
        "        print('Cats:',dogsvcats.catcount)\n",
        "        print('Dogs:',dogsvcats.dogcount)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # just run the init of parent class (nn.Module)\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "\n",
        "        x = torch.randn(50,50).view(-1,1,50,50)\n",
        "        self._to_linear = None\n",
        "        self.convs(x)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
        "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
        "\n",
        "    def convs(self, x):\n",
        "        # max pooling over 2x2\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
        "\n",
        "        if self._to_linear is None:\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "\n",
        "net = Net().to(device)\n",
        "print(net)\n",
        "\n",
        "if REBUILD_DATA:\n",
        "    dogsvcats = DogsVSCats()\n",
        "    dogsvcats.make_training_data()\n",
        "\n",
        "#####################\n",
        "\n",
        "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
        "print(len(training_data))\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in training_data])\n",
        "\n",
        "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
        "val_size = int(len(X)*VAL_PCT)\n",
        "\n",
        "train_X = X[:-val_size]\n",
        "train_y = y[:-val_size]\n",
        "\n",
        "test_X = X[-val_size:]\n",
        "test_y = y[-val_size:]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n",
            "24946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L2aIBpYw_TK",
        "colab_type": "code",
        "outputId": "15f5ef3c-fb8e-4e48-99ea-ba2dbfc6e940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "EPOCHS = 15\n",
        "\n",
        "def train(net):\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "    BATCH_SIZE = 100\n",
        "    EPOCHS = 15\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i in range(0, len(train_X), BATCH_SIZE): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
        "            #print(f\"{i}:{i+BATCH_SIZE}\")\n",
        "            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
        "            batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)  # 移到gpu上\n",
        "            net.zero_grad()\n",
        "\n",
        "            optimizer.zero_grad()   # zero the gradient buffers\n",
        "            outputs = net(batch_X)\n",
        "            loss = loss_function(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()    # Does the update\n",
        "\n",
        "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "train(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0. Loss: 0.12146426737308502\n",
            "Epoch: 1. Loss: 0.1136816218495369\n",
            "Epoch: 2. Loss: 0.11111681163311005\n",
            "Epoch: 3. Loss: 0.08594635874032974\n",
            "Epoch: 4. Loss: 0.0765075534582138\n",
            "Epoch: 5. Loss: 0.06880223006010056\n",
            "Epoch: 6. Loss: 0.054771386086940765\n",
            "Epoch: 7. Loss: 0.08309535682201385\n",
            "Epoch: 8. Loss: 0.11497875303030014\n",
            "Epoch: 9. Loss: 0.06833942234516144\n",
            "Epoch: 10. Loss: 0.04078666493296623\n",
            "Epoch: 11. Loss: 0.03021884709596634\n",
            "Epoch: 12. Loss: 0.015845494344830513\n",
            "Epoch: 13. Loss: 0.03258278965950012\n",
            "Epoch: 14. Loss: 0.00563669903203845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8G17SkfvFPY",
        "colab_type": "code",
        "outputId": "d78f1af3-cbc8-49f9-e43d-1e6b4a8c2976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_X.to(device)\n",
        "test_y.to(device)\n",
        "\n",
        "def test(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(test_X))):\n",
        "            real_class = torch.argmax(test_y[i]).to(device)\n",
        "            net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]  # returns a list, \n",
        "            predicted_class = torch.argmax(net_out)\n",
        "\n",
        "            if predicted_class == real_class:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    print(\"Accuracy: \", round(correct/total, 3))\n",
        "\n",
        "test(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2494/2494 [00:02<00:00, 902.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJeQ2s_dyztE",
        "colab_type": "code",
        "outputId": "37283db9-5a1a-475b-ac65-07f2ee39c9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_X=test_X.to(device)\n",
        "test_y=test_y.to(device)\n",
        "\n",
        "def test(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(test_X))):\n",
        "            real_class = torch.argmax(test_y[i]).to(device)\n",
        "            net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]  # returns a list, \n",
        "            predicted_class = torch.argmax(net_out)\n",
        "\n",
        "            if predicted_class == real_class:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    print(\"Accuracy: \", round(correct/total, 3))\n",
        "\n",
        "test(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2494/2494 [00:02<00:00, 968.38it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_XpATs3vFSF",
        "colab_type": "code",
        "outputId": "ca090ee9-afe2-45db-cc0f-31c497e3f193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for i in tqdm(range(0, len(test_X), BATCH_SIZE)):\n",
        "\n",
        "    batch_X = test_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50).to(device)\n",
        "    batch_y = test_y[i:i+BATCH_SIZE].to(device)\n",
        "    batch_out = net(batch_X)\n",
        "\n",
        "    out_maxes = [torch.argmax(i) for i in batch_out]\n",
        "    target_maxes = [torch.argmax(i) for i in batch_y]\n",
        "    for i,j in zip(out_maxes, target_maxes):\n",
        "        if i == j:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "print(\"Accuracy: \", round(correct/total, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:00<00:00, 80.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OavqAQjzPTq",
        "colab_type": "text"
      },
      "source": [
        "## p8 Basic Network Analysis and Visualizations - Deep Learning and Neural Networks with Python and Pytorch p.8\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGOjV5PPt0KL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://pythonprogramming.net/analysis-visualization-deep-learning-neural-network-pytorch/?completed=/gpu-deep-learning-neural-network-pytorch/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bdyaZok9lRjC",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoPtIgWEt0Ib",
        "colab_type": "code",
        "outputId": "1da2e85e-3a75-4b97-ecac-02f6e44b0350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "REBUILD_DATA = False # set to true to one once, then back to false unless you want to change something in your training data.\n",
        "\n",
        "class DogsVSCats():\n",
        "    IMG_SIZE = 50\n",
        "    CATS = \"PetImages/Cat\"\n",
        "    DOGS = \"PetImages/Dog\"\n",
        "    TESTING = \"PetImages/Testing\"\n",
        "    LABELS = {CATS: 0, DOGS: 1}\n",
        "    training_data = []\n",
        "\n",
        "    catcount = 0\n",
        "    dogcount = 0\n",
        "\n",
        "    def make_training_data(self):\n",
        "        for label in self.LABELS:\n",
        "            print(label)\n",
        "            for f in tqdm(os.listdir(label)):\n",
        "                if \"jpg\" in f:\n",
        "                    try:\n",
        "                        path = os.path.join(label, f)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
        "                        #print(np.eye(2)[self.LABELS[label]])\n",
        "\n",
        "                        if label == self.CATS:\n",
        "                            self.catcount += 1\n",
        "                        elif label == self.DOGS:\n",
        "                            self.dogcount += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "                        #print(label, f, str(e))\n",
        "\n",
        "        np.random.shuffle(self.training_data)\n",
        "        np.save(\"training_data.npy\", self.training_data)\n",
        "        print('Cats:',dogsvcats.catcount)\n",
        "        print('Dogs:',dogsvcats.dogcount)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "\n",
        "        x = torch.randn(50,50).view(-1,1,50,50)\n",
        "        self._to_linear = None\n",
        "        self.convs(x)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)\n",
        "\n",
        "    def convs(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
        "\n",
        "        if self._to_linear is None:\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, self._to_linear)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net = Net().to(device)\n",
        "\n",
        "if REBUILD_DATA:\n",
        "    dogsvcats = DogsVSCats()\n",
        "    dogsvcats.make_training_data()\n",
        "\n",
        "training_data = np.load(\"/content/drive/My Drive/Colab Notebooks/sentdex/training_data.npy\", allow_pickle=True)\n",
        "print(len(training_data))\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in training_data])\n",
        "\n",
        "VAL_PCT = 0.1\n",
        "val_size = int(len(X)*VAL_PCT)\n",
        "print(val_size)\n",
        "\n",
        "train_X = X[:-val_size]\n",
        "train_y = y[:-val_size]\n",
        "\n",
        "test_X = X[-val_size:]\n",
        "test_y = y[-val_size:]\n",
        "\n",
        "print(len(train_X))\n",
        "print(len(test_X))\n",
        "\n",
        "\n",
        "def train(net):\n",
        "    BATCH_SIZE = 100\n",
        "    EPOCHS = 3\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
        "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
        "            batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "            net.zero_grad()\n",
        "            outputs = net(batch_X)\n",
        "            loss = loss_function(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(loss)\n",
        "\n",
        "def test(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(test_X))):\n",
        "            real_class = torch.argmax(test_y[i]).to(device)\n",
        "            net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]\n",
        "\n",
        "            predicted_class = torch.argmax(net_out)\n",
        "            if predicted_class == real_class:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    print(\"Accuracy:\", round(correct/total,3))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n",
            "24946\n",
            "2494\n",
            "22452\n",
            "2494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91f6yNTom0ql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "2584b012-cd8f-4bd9-e1f9-7b48b9c97917"
      },
      "source": [
        "net = net.to(device)\n",
        "\n",
        "def train(net):\n",
        "    BATCH_SIZE = 100\n",
        "    EPOCHS = 3\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
        "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
        "            batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "            net.zero_grad()\n",
        "            outputs = net(batch_X)\n",
        "\n",
        "            matches  = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, batch_y)]\n",
        "            in_sample_acc = matches.count(True)/len(matches)\n",
        "\n",
        "            loss = loss_function(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(loss)\n",
        "        print(\"In-sample acc:\",round(in_sample_acc, 2))\n",
        "\n",
        "train(net)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:06<00:00, 32.93it/s]\n",
            "  2%|▏         | 4/225 [00:00<00:06, 34.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1837, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "In-sample acc: 0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:06<00:00, 33.14it/s]\n",
            "  2%|▏         | 4/225 [00:00<00:06, 35.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1299, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "In-sample acc: 0.88\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:06<00:00, 34.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1005, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "In-sample acc: 0.88\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3T6j5nqm010",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cdb0643-9b00-4164-fac8-94576f50d8c3"
      },
      "source": [
        "def batch_test(net):\n",
        "    BATCH_SIZE = 100\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        #np.random.shuffle(test_X)\n",
        "        #np.random.shuffle(test_y)\n",
        "\n",
        "        batch_X = test_X[:BATCH_SIZE].view(-1,1,50,50)\n",
        "        batch_y = test_y[:BATCH_SIZE]\n",
        "\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        net.zero_grad()\n",
        "        outputs = net(batch_X)\n",
        "\n",
        "        matches  = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, batch_y)]\n",
        "        acc = matches.count(True)/len(matches)\n",
        "\n",
        "        print(\"Test Accuracy:\", round(acc, 3))\n",
        "\n",
        "\n",
        "batch_test(net)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k_qvVHxm07P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fwd_pass(X, y, train=False):\n",
        "\n",
        "    if train:\n",
        "        net.zero_grad()\n",
        "    outputs = net(X)\n",
        "    matches  = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, y)]\n",
        "    acc = matches.count(True)/len(matches)\n",
        "    loss = loss_function(outputs, y)\n",
        "\n",
        "    if train:\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return acc, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PU9OfVhm0_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c4f3adae-fe4b-4c48-9b54-c09d9ccc264b"
      },
      "source": [
        "net = Net().to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "def train(net):\n",
        "    BATCH_SIZE = 100\n",
        "    EPOCHS = 3\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
        "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
        "            batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "            acc, loss = fwd_pass(batch_X, batch_y, train=True)\n",
        "\n",
        "            print(f\"Acc: {round(float(acc),2)}  Loss: {round(float(loss),4)}\")\n",
        "\n",
        "            # just to show the above working, and then get out:\n",
        "            if i == 5:\n",
        "                break\n",
        "            break\n",
        "\n",
        "train(net)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/225 [00:00<?, ?it/s]\n",
            "  0%|          | 0/225 [00:00<?, ?it/s]\n",
            "  0%|          | 0/225 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.52  Loss: 0.2499\n",
            "Acc: 0.52  Loss: 0.2496\n",
            "Acc: 0.6  Loss: 0.2485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boEXPqtTm1IH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw78BsnEm1MA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTP-YU5nm1Fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9W0zgVxm05h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}